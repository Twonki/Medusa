=============
= Episodes: =
=============
50



==============
= Optimizer: =
==============
SGD



============================
= Optimizer Configuration: =
============================
optimizer = torch.optim.SGD(model.parameters(), 
                                0.01, # learning rate (2nd trial)
                                momentum=0.9,
                                weight_decay=1e-6) # decay (2nd trial)



=============================
= Learning Rate Adjustment: =
=============================
def adjust_learning_rate(optimizer, epoch):
    """Sets the learning rate to the initial LR decayed by 10 every 30 epochs"""
    lr = 0.01 * (0.1 ** (epoch // 30)) # first value is learning rate (2nd trial)

    for param_group in optimizer.param_groups:
        param_group['lr'] = lr



===============
= Batch Size: =
===============
100
