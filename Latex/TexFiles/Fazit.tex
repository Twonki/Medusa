\chapter{Fazit}
\label{cha:Fazit} \label{cha:Schluss}
Nach einer abschließenden Zusammenfassung, werden in diesem Kapitel zusätzlich die verschiedenen Ansätze verglichen und bewertet. Aus dieser Diskussion werden die Einschränkungen und Möglichkeiten für weitere Arbeiten angesprochen.

\section{Zusammenfassung} ~\newline 
Mit der Degeneration konnte ein simpler Algorithmus erstellt werden, welcher zuverlässig gute Ergebnisse liefert. 
Der wesentliche Vorteil der Degeneration ist die Unabhängigkeit vom Model - man muss nicht zuerst ein Transfermodel erstellen, um Angriffe zu erzeugen, sondern kann diese anhand der vorliegenden \textit{Blackbox} generieren.  

Der primäre Nachteil der Degeneration liegt in dem Zeitaufwand: Für einen \textit{guten} Angriff musste über eine Stunde gearbeitet werden. \textit{Bessere} Netze können zusätzlich empfindlicher auf Rauschen reagieren, und dementsprechend die Zeiten weiter erhöhen. 
  
Dennoch ist die Effektivität der Degeneration überraschend - immerhin ist es im wesentlichen ein Brute-Force Angriff. 

~\newline Desweiteren konnten Erfolge mit der Erzeugung von Saliency Maps in den geglätteten Varianten verbucht werden. Somit konnte bestätigt werden, dass die Visualisierung der relevanten Pixel für ein Bild mit hoher Konfidenz geeignet sind, um als \textit{minimale Beispiele} für das NN verwendet werden können. 
Die entsprechenden Verfahren erzeugten Täuschungen mit Konfidenzen >0.9, allerdings lassen sich keine Aussagen über die allgemeine Verlässlichkeit und Zielgerichtetheit treffen.

Zuletzt konnte auch mit dem \textit{Gradient Ascent} Verfahren sehr gute Ergebnisse erzielt werden. Für 10 von 43 Klassen konnten Täuschungen mit hohen Konfidenzen am Remote-NN erzielt werden. Es wird vermutet, dass die Ausbeute mit weiterer Optimierung vergrößert werden kann oder auch echte Bilder für die Erzeugung der Täuschungen verwendet werden können.

\section{Diskussion}
Die Herausforderungen des Wettbewerbs wirken sich auf die Erfolge der Verfahren aus. Es wird vermutet das beide Verfahren \textit{Saliency Map} und \textit{Gradient Ascent} bessere Ergebnisse liefern könnten, wenn das verwendete Bild größer als $64\times64$ wäre. Desweiteren kann nichts über die Validierungsgenauigkeit des \ac{NN} des Wettbewerbs gesagt werden, weshalb auch die nicht zielgerichteten Täuschungsbilder als gutes Ergebnis betitelt werden. 


Im Vergleich der Methoden \textit{Saliency Map} und \textit{Gradient Ascent}, kann das letztere Verfahren bevorzugt werden. 

~\newline Diese Methoden lassen sich schwer mit der Degeneration vergleichen - die schnelleren Erfolge werden voraussichtlich mithilfe der Degeneration erzeugt, da sie deutlich weniger Vorlauf benötigt.
Nachdem allerdings das entsprechende Umfeld (eigenes Netz, Bibliotheken und Code) erzeugt wurde, können innerhalb des Gradient Ascent Foolings deutlich schneller zuverlässige Bilder erzeugt werden.  
%content 
%vergleich der ergebnisse (reproduzierbarkeit, gezielt/random, qualität der bilder) - einschränkungen probleme unserer ansätze, wichtig: eigene fehler oder einschränkungen der methodik erkennen.



\section{Weiterführende Arbeiten}~\newline 
Die Ergebnisse dieser Arbeit liefern weitere Ansätze für zukünftige Aufgaben. Zum einen können die verwendeten Ansätze individuell weiter optimiert werden, bezüglich des selbsterstellten lokalen neuronalem Netz und der Algorithmik bzw. deren Parameter. Desweiteren können verfahren entwickelt werden, die sich aller Methoden gezielt bedienen. 

~\newline Eine insgesamt spannende Arbeit wäre die Anwendung von Adversarial Attacks auf Sprachassistenten. 
Vor allem die Degeneration kann bereits in ihrem jetzigen Zustand genutzt werden, um Störgeräusche zu erzeugen, welche dennoch als Schlüsselwörter erkannt werden und ein \textit{Smarthome} hacken. 

Auch die anderen Verfahren sind insbesondere geeignet, sollte das Model offenliegen. Der Sprachassistent-Hersteller Mycroft setzt auf Open-Source, und stellt dementsprechend auch das (allgemeine) Model bereit. 
Zu bemerken ist hierbei noch, das der Nutzer innerhalb der ersten Aktionen den Sprachassistenten auf seine Aussprache konfiguriert.  

~\newline An der Degeneration können ebenfalls großflächige Weiterentwicklungen vorgenommen werden: 

Zum einen die Verwendung der Tree-Degeneration, zum anderen können Beschleunigung und Verfall der einzelnen Alternations eingebaut werden. Ebenso sollte ein kleines Script erstellt werden, welche die verschiedenen Manipulationsfunktionen kurz auslotet und dem Nutzer vorstellt. 

Als komplexere Weiterentwicklung können mithilfe der Degeneration \textit{Manipulationsvektoren} erstellt werden und in einem Raum abgebildet werden. Hierbei stellt jedes \textit{Rauschen} (bzw. Bilddifferenz) und die Score-Differenz einen Vektor dar, welcher in einem Raum abgebildet werden kann.   

Mithilfe dieser Vektoren könnte über statistische bzw. numerische Verfahren solch ein Vektor gefunden werden, welcher die größte Länge hat allerdings die geringste Score-Differenz auweißt. Angewandt auf das Urbild sollte dieser Vektor ein optimales Ergebnis erzielen.  

~\newline Einen weiteren Blick sollte man der Überführbarkeit der Angriffe von einem lokalen Model auf ein unbekanntes Model widmen, wie sie in \ref{sec:TrasiModell} angeschnitten wurde: 

Diese Eigenschaft wurde von den Saliency-Maps und dem Gradient Ascent Fooling hinreichend erfüllt, dahingegen scheiterten eben solche Versuche der Degeneration. 

Im Rahmen dieses Ergebnisses könnte man einen gezielten Test der Verfahren auf zwei bekannte Modelle durchführen, um hier transparentere Werte zu erhalten und Gründe für dieses Verhalten auszumachen. 
%content
%Vergleich mit einem Framework, wie zum Beispiel CleverHans \footnote, Vergleich von einem gut und schlecht trainierten Modell, wie arg unterscheiden sich daraus generierte Bilder (lohnt es sich), wie wichtig ist die Bildgröße, 