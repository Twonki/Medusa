\chapter{Degeneration}
Innerhalb dieses Kapitels wird der Ansatz der \textit{Degeneration} vorgestellt.

Die Benennung schöpft sich aus der Nähe zu genetischen Algorithmen \todo{genauer, was das ist?}, allerdings aus einer invertierten Perspektive: Um auf unbekannte Modelle einzugehen, wird hierbei von einem korrekt erkannten Bild \textit{weggearbeitet}.

~\newline Zunächst wird das Konzept anhand von Pseudocode genauer erläutert. Anschließend wird die Implementierung des Algorithmus für die Verwendung der unbekannten Trasi-AI vorgestellt, und den Abschluss dieses Kapitels bildet eine lokale Implementierung zuzüglich einiger Verbesserungen, welche sich aufgrund der Limitierungen des Zugriffes auf die \textit{remote-AI} nicht angeboten haben.
\section{Konzept}
Die Grundlegende Idee des Algorithmus bezieht sich darauf, ein Urbild $i$ zu einem Abbild $\hat{i}$ zu manipulieren, welches von dem unbekannten Klassifizierungsalgorithmus weiterhin korrekt erkannt wird. 

~\newline Abhängig von der Stärke der Manipulation soll eine $Tiefe$ gewählt werden, ab welcher der Algorithmus beendet wird. Als Beispiele der Manipulation seien insbesondere Rauschen und Glätten genannt, allerdings auch Kantenschärfung und Veränderungen der Helligkeit und anderer Metaparameter. 

~\newline Mit fortschreitender Tiefe wird nahezu jedes Bild unkenntlich. Zusätzlich sollten allerdings weitere Parameter als Abbruchkriterien aufgenommen werden, konkret eine Anzahl an Gesamt-Iterationen und ein Abbruch, sollten keine weiteren Fortschritte erreicht werden.

\newpage
\paragraph{Pseudocode} ~\newline 
Folgende Parameter erwartet unsere (generische) Implementierung des Degeneration-algorithmus: 
\begin{itemize}
	\item Einen Eingabewert $i$
	\item Eine Manipulations-Funktion $a : i \rightarrow \hat{i}$
	\item Eine Klassifizierungsfunktion $p : i \rightarrow \mathrm{R}$
	\item Eine gewünschte Tiefe $d$ (empfohlen, nicht notwendig)
	\item Eine Iterationszahl $its$ (empfohlen, nicht notwendig)
	\item Ein Schwellwert $t$ , um wie viel \% die Vorhersage schlechter sein darf, als das vorhergegangene Bild 
\end{itemize}
Auf einige der Punkte wird in den Anmerkungen gesondert eingegangen. ~\newline
\IncMargin{1em}
\begin{algorithm}
	\SetKwInOut{Input}{input}
	\SetKwInOut{Output}{output}
	\Input{i,a,p,d,its,t}
	\Output{$\hat{i}$, score}
	\BlankLine
	$depth  \leftarrow 0$, $loop \leftarrow0$ \;
	$s \leftarrow p(i)$\;
	$ii \leftarrow i , is \leftarrow s$ \;
	\While{$depth<d ~ || ~ loop <its$}{
		$ai \leftarrow a(i)$ \;
		$as \leftarrow p(ai)$ \;
		\If{$as >= is-t$}{
			$is \leftarrow as$\;
			$ii \leftarrow ai$\;
			depth++\;
		}
		loop ++\;
	}
	return ii,is\;
	
	\caption{Degeneration}\label{algo_degen}
\end{algorithm}\DecMargin{1em}
\newpage
\paragraph{Anmerkungen}~\newline 
Die Manipulationsfunktionen müssen genau ein Bild der Größe (x,y) erhalten und genau ein Bild der Größe (x,y) wiedergeben, und (für die generischen Implementierungen) keine weiteren Parameter erhalten. 

Zusätzlich sollte die Manipulationsfunktion zufällige Elemente erhalten. Sollte eine einfache,idempotente Glättungsfunktion den Schwellwert nicht erfüllen, so wird niemals eine größere Tiefe erreicht.  

~\newline Tiefe, Schwellwert und Manipulationsfunktion müssen aufeinander abgestimmt werden. Es gibt einige Funktionen, welche eine starke Veränderung hervorrufen, und für welche eine geringe Tiefe bereits ausreicht. Auf der anderen Seite dieses Spektrums können Funktionen, welche lediglich minimale Änderungen vornehmen, schnell große Tiefen erreichen, ohne ein merklich verändertes Bild hervorgerufen zu haben. 

Diese Parameter auszubalancieren obliegt dem Nutzer. 

Bei der Auswahl der Parameter sollte zusätzlich überschlagen werden, wie groß die letztendliche Konfidenz ist, falls die maximale Tiefe erreicht wird. 

~\newline Innerhalb der Implementierungen sollte zusätzlich eine \textit{verbose}-Funktion eingebaut werden. Hiermit kann zum einen ein ergebnisloser Versuch frühzeitig erkannt werden, und zusätzlich, ob der Algorithmus sich festgefahren hat. Üblicherweise kann man erkennen, wenn die Manipulationsfunktion \textit{zu stark} ist (bzw. der Schwellwert zu niedrig gewählt wurde).

~\newline Der oben genannte Algorithmus lässt sich auch für Text- oder Sprach-basierte Klassifikationen adaptieren. 

Hierfür müssen lediglich andere Manipulations- und Klassifizierungs-Funktionen gewählt werden.
\newpage
\section{Implementierung Remote}
Im Rahmen des Wettbewerbs wurde mit einer Rest-API \todo{Marker nach oben} gearbeitet, welche besondere Herausforderungen mit sich bringt: 

\begin{itemize}
	\item Anfragen können fehlschlagen
	\item zwischen Anfragen muss ein Timeout liegen
	\item Mehrere Nutzer, welche die API beanspruchen, blockieren sich
\end{itemize}
~\newline
Zusätzlich wurde der Grundalgorithmus um die \textit{Verbose}-Funktion und eine History erweitert. Mithilfe der \textit{History} können anschließend hilfreiche Plots erstellt werden. 

Diese wurden für den untenstehenden Code weggelassen.
~\newline~\newline
Ebenso ist anzumerken, das ignoriert wurde, welche Klasse zuerst erzeugt wurde. Solange irgendeine Klasse mit einer passenden Konfidenz gefunden wurde, wird dies als hinreichend erachtet. Im Normalfall bleibt es allerdings bei derselben Klasse. 

~\newline 
Die Klassifizierungsfunktion wird innerhalb der Remote-Degeneration durch einige Hilfsfunktionen umgesetzt. Diese bereiten ein als \textit{Bytearray} vorliegendes Bild entsprechend auf und senden es an das Trasi-Webinterface (Die Methode \textit{Scorer.Send\_ppm\_image(img)}) und gibt ein JSON-Array der Scores wieder. 

Die Hilfsmethode \textit{Scorer.get\_best\_score(response)} gibt den höchsten gefunden Score wieder.
\newpage
\begin{small}
\improvement{Zeilennummern, Caption}
\pythonexternal{CodeSnippets/remoteDegenerationSnippet.py}
\end{small}
\section{Ergebnisse Remote}
In diesem Abschnitt werden die mit der Degeneration erzielten Ergebnisse in Bezug auf die Trasi-Schnittstelle vorgestellt. Zunächst werden einige positive Beispiele (Erfolge) gezeigt, anschließend einige Probleme die aufgetreten sind und zuletzt noch ein Zwischenfazit gezogen. 
\paragraph{Positive Ergebnisse} ~\newline Hier kommen einige positive Beispiele rein, die mit Rauschen und/oder Smoothen erzeugt wurden. Unbedingt mit Zeiten, Iterationen und dem Plot (Insofern muss man die am besten mal abspeichern aus der Spielwiese, )
Hier kommen ein paar Beispiele und Plots. 

\paragraph{Negative Ergebnisse} ~\newline Es gab zwei primäre Fehlerquellen in Bezug auf die Remote-Degeneration: Die Auswahl von Bildern, welche im GTSRB-\textit{Training}-Set waren, sowie die Auswahl ungeeigneter Manipulationsfunktionen. 
~\newline
Die AI innerhalb der Schnittstelle scheint sich die Bilder aus dem Trainingsset \textit{gemerkt} zu haben. Bereits minimale, unwichtige Änderungen des Schildes (z.B. einfügen einiger blauer Punkte im Hintergrund) führen zu einer drastischen Verschlechterung des Ergebnisses \todo{Beispielbild mit Scores!}. Dieses starke \textit{Ausschlagen} des Scores machte die Benutzung der Degeneration unbrauchbar.
~\newline
Dieses Problem hat sich herauskristallisiert, als über einen längeren Zeitraum (\~ 10 Stunden) kein Bild erzeugt wurde, welches auch nur leicht verändert wurde. Die einzigen Änderungen, welche erzielt wurden, waren innerhalb des weißen Bereiches des Überholverbotsschildes \todo{Beispielbild!}. Es wurden aber ebenfalls keine Änderungen vorgenommen außerhalb des Schildes, wo diese zu erwarten wären und bei vorhergehenden Versuchen auch zu beobachten waren. 
~\newline
Dieses Problem tritt ausschließlich (allerdings zuverlässig) bei der Verwendung von Bildern aus dem Trainingsset auf. Es tritt nicht auf sobald man Bilder aus dem Test-Set verwendet oder \textit{GTSRB-fremde} Bilder (vorausgesetzt, sie besitzen eine akzeptable Startkonfidenz). 

Innerhalb der lokalen Implementierung ist dieses Problem ebenfalls aufgetreten, konnte allerdings behoben werden, sobald man das Overfitting erkannt hatte. 
\paragraph{Fazit} ~\newline
Innerhalb dieses kurzen Zwischenfazits sollen noch einmal die Vor- und Nachteile der Degeneration zusammengefasst werden: ~\newline ~\newline  
\begin{tabular}{|p{7.5cm}|p{7.5cm}|}
	\hline 
	\textbf{Vorteile} & \textbf{Nachteile} \\ 
	\hline 
	\textbf{Model-Agnostic:} Der Algorithmus funktioniert unabhängig und ohne Wissen über das zugrundeliegende Modell & \textbf{Zeitintensiv:} \newline v.A. die Remote-Variante benötigt größere Zeitspannen \\ 
	\hline 
	\textbf{Kontext-Unabhängig:} Die Herangehensweise ist nicht auf Bilderkennungen limitiert & \textbf{Vorwissen benötigt:} Der Sinn des zugrundeliegenden Models muss bekannt sein, und ein geeignetes Startbild muss ausgewählt werden  \\ 
	\hline 
	\textbf{Erweiterbar:} Die Manipulationsfunktionen können weiter ausgebaut werden und haben noch großes Potenzial & Die Degeneration erzielt bei empfindlichen Modellen schlechter Ergebnisse - gerade \textit{professionelle} Modelle sollten lange brauchen, um so überlistet zu werden \\ 
	\hline 
	\textbf{Simple:} Der Algorithmus ist einfach implementiert und erläutert, er benötigt keine höhere Mathematik oder Vorwissen zur Thematik \textit{Machine Learning}& Im Remote-Umfeld kann die Degeneration als DDoS wahrgenommen werden und entsprechend frühzeitig unterbunden werden. \\ 
	\hline 
\end{tabular}

\newpage
\section{Implementierung Lokal}
Ich weiß nicht ob das ein extra Punkt ist, aber an sich würde ich hier das Model bei uns kurz vorstellen

\section{Anpassung und Verbesserung Lokal}
Hier kommen zunächst so Dinge wie "wait" rauszunehmen aber GPU-Acceleration würde ich auch hernehmen. 
\subsection{Batch-Degeneration}
Ist noch ein To-Do: Degenerieren von 100 Bildern, Wahl des "besten". Mach ich noch.
\subsection{Parallel-Degeneration}
Nur Ansatz: Hat nicht geklappt das zu basteln weil numpy Arrays echt nervig sind bei Parallelverarbeitung. 

Vorstellen kann man das allerdings kurz. Konflikt mit GPUAcceleration. 