\chapter{Technisches Konzept}
\section{Verwendete Technologien}
Die Umsetzung der Implementierung erfolgt innerhalb der webbasierten, interaktiven Entwicklungsumgebung Jupyter Notebook \footnote{https://jupyter.org/} (in der Version 5.7.4) zusammen mit der objektorientierten höheren Programmiersprache Python \footnote{https://www.python.org/} (in der Version 3.6.5).


Jupyter Notebook bietet aufgrund seiner plattformübergreifenden Einsatzmöglichkeit und Kompatibilität zu allen gängigen Webbrowsern eine hohe Flexibilität, was die Darstellung und Ausführung von Python-Code angeht. Darüber hinaus bietet Python eine hohe Verfügbarkeit von Open-Source-Repositories im Bereich Datenverarbeitung, Machine Learning und Deep Learning \ref{todo}. Die Programmiersprache wurde ferner im Rahmen der StackOverflow Befragung 2017 von den befragten Softwareentwicklern zur fünftbeliebtesten Technologie des Jahres 2017 gewählt \ref{todo}. Nicht zuletzt ist Python und die inbegriffenen umfangreichen Standardbibliotheken auf allen gängigen Plattformen, wie beispielsweise Linux, Apple MacOS und Microsoft Windows, kostenlos und in quell- oder binärform verfügbar \ref{todo}.


Als Paketmanager wurde die frei verfügbare Anaconda Distribution in der derzeit aktuellsten Version 2018.12 gewählt, da sie eine vereinfachte Paketinstallation und -verwaltung ermöglicht. Darüber hinaus bietet Anaconda die Möglichkeit Jupyter Notebooks sowie Python und dessen verfügbare Pakete in verschiedenen Entwicklungs- und Testumgebungen isoliert voneinander zu verwalten und zu betreiben \ref{todo}. Schließlich erlaubt “Anaconda Accelerate” den programmatischen Zugriff auf numerische Softwarebibliotheken zur beschleunigten Codeausführung auf Intel Prozessoren sowie NVIDIA Grafikkarten \ref{todo}.


Zur fehlerfreien Ausführung des Codes (Saliency Map Verfahren beziehungsweise Gradient Ascent Verfahren) müssen sowohl Python 3.6.5 als auch folgende Python-Bibliotheken in der wie folgt spezifizierten Version in der zur Laufzeit verwendeten Anaconda Environment vorliegen, wie in Tabelle \ref{tabelle} aufgeschlüsselt.


\begin{table}
	\centering
	\begin{tabular}{|l|l|p{10.4cm}|}
		\hline 
		Name & Version & Beschreibung \\ 
		\hline\hline 
		Keras& 2.2.4  & Enthält Funktionen für Deep-Learning Anwendungen [7] \\ 
		\hline 
		Torchvision& 0.2.1 & Enthält Datensätze, Modellarchitekturen und gängige Bildtransformationsoperationen für Computer-Vision Anwendungen [8] \\ 
		\hline 
		OpenCV& 3.4.2  & Enthält Funktionen für echtzeit Computer-Vision Anwendungen [9] \\ 
		\hline 
		NumPy&  1.15.3& Enthält Funktionen zur effizienten Durchführung von Vektor- oder Matrizenberechnungen [10] \\ 
		\hline 
		Requests& 2.18.4 & Enthält Funktionen zur Vereinfachung von HTTP Requests [11] \\ 
		\hline 
		Pillow& 5.2.0 & Enthält Funktionen zum laden, modifizieren und speichern von verschiedenen Bilddateiformaten [12] \\ 
		\hline 
		Matplotlib& 2.2.3 & Enthält Funktionen zum Plotten von Graphen oder Bildern [13] \\ 
		\hline 
		SciPy& 1.1.0  & Enthält wissenschaftliche und technische Funktionen zur Datenverarbeitung [14] \\ 
		\hline 
	\end{tabular} 
	\caption{Paketabhängigkeiten der implementierten Software}
	\label{tab:parameter}
\end{table}

Um die Voraussetzungen zur benötigten Python Version respektive der erforderlichen Python-Bibliotheken zu erfüllen, muss beim ersten Öffnen des Jupyter Notebooks zum Saliency Map Verfahren beziehungsweise zum Gradient Ascent Verfahren immer der Code zur Rubrik “Managing Anaconda Environment” zuerst ausgeführt werden. Andernfalls kann die korrekte Ausführung von weiteren Teilen des Codes in nachfolgenden Rubriken nicht gewährleistet werden.

\section{Transferierbarkeit von Angriffen auf ein Blackbox Modell}


\label{sec:TrasiModell}
Eine Herausforderung des Wettbewerbs ist der Umgang mit dem zu täuschenden Neuronalen Netz. Die oberflächliche Analyse der Web-Schnittstelle ermöglicht keine genauen Informationen über die verwendete Architektur oder anderen Details. Dennoch wurde bereits bestätigt, dass es selbst für “Blackbox” Modelle möglich ist, Irrbeispiele und Bilder zu erzeugen.

Papernot \& Goodfellow et al.[https://arxiv.org/pdf/1602.02697.pdf][] bestätigten, dass Täuschungen auf ein bekanntes Netz mit hoher Wahrscheinlichkeit auch auf fremden Modellen fehlklassifiziert werden, also dass die Ergebnisse nicht nur ein zufälliges Ereignis aufgrund von Overfitting des spezifischen Neuronalen Netzes sind. Die Ergebnisse wurde an verschiedenen Modelltypen getestet (LR, SVM, DNN) und zeigten immer eine - in ihrer ausprägung schwankende- korrelation zwischen Fehlklassifikation auf einem fremden modell im vergleich zu bekannten Modellen. 

Diese Ergebnisse führten zu dem Entschluss, ein eigenes Neuronales Netz zu modellieren, welches als Substitute (dt. Ersatz) dient.

Transferability https://openreview.net/pdf?id=Sys6GJqxl

Blackbox Attacks: https://arxiv.org/pdf/1602.02697.pdf

\section{Implementierung eines eigenen Modells zur Klassifizierung von Straßenschildern (Aphrodite)}
Für die lokale Degeneration in Kapitel \ref{cha:Degeneration} wurde mithilfe Tensorflows ein eigenes Keras-Model erstellt zur Verkehrsschilderkennung. \todo{at Peter: Bezug der Aphrodite in Gradient Ascent Fooling?}

~\newline Das (am meisten verwendete) Modell \textit{Aphrodite} umfasst vier Convolutional-Layer, drei Dense-Layer und zuletzt im Ausgabelayer eine Softmax-Funktion für die 43 Klassen. Ein detaillierter Aufbau des Netzes befindet sich im Anhang\todo{Netzzusammenfassung als Tabelle in den Anhang}\todo{Link in den Anhang}.

~\newline Für das Training wurden die GTSRB-Trainings- und Test-Daten verwendet. Diese wurden um die richtige Auflösung zu erreichen auf 64x64 interpoliert. 

Da nicht sicher war, welche Interpolationsfunktion innerhalb der Remote-Schnittstelle verwendet wurde, wurde für das Training jedes Bild mehrfach interpoliert und ebenfalls mehrfach für das Training verwendet. Für die Testdaten wurde eine zufällige Interpolationsfunktion ausgesucht. 

~\newline \textit{Aphrodite} erreichte eine Genauigkeit von 96.5 \% auf die Trainingsdaten. Eine Übersicht über die Trainingsparameter findet sich im Repository unter /DegenerationCode/Training.py. \todo{Sollte man das anders schreiben? Oder packen wir das file in den Anhang?}

~\newline Der Name Aphrodite wurde gewählt, um dem ersten Modell (Model A) innerhalb des Projektes einen sprechenden Namen zu geben.

\todo{ANPE: Das ALEXNET-Model hier auch listen?}