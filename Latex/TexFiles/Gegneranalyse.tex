\chapter{Analyse der Webschnittstelle}
\label{cha:TrasiAnalyse}
In das Kapitel kommen die Dinge die wir über die Trasi-AI wissen
\section{Eigenschaften des bereitgestellten Neuronalen Netz}
\label{sec:TrainingsDaten}




33 verschiedene aufgezeichnete klassenlabels (im vergleich GTSRB datensatz 43)

\begin{enumerate}
	\item 
	Aus der aufgabenstellung 64x64x3
	\item 
	bilder aus dem GTSRB [quelle] datensatz
	\item Gekürzte Klassen: Aus der analyse geht die Vermutung hervor, dass nur 33 Klassen unterschieden werden, keine 43 wie im orginal datensatz
	\item Softmax-Ausgabefunktion 
	\item Interpolationsfunktion (vllt mit einem Bild in 3 Interpolationsversionen und jeweiligen Score) 
	\item Overfitting bei Trainingsdaten
	\item unzuverlässigkeit bei nicht-Schildern (z.B. OhmLogo)
\end{enumerate}

\section{Transferierbarkeit von Angriffen auf ein Blackbox Modell}
\label{sec:TrasiModell}
Verwandte arbeiten bestätigen  die Transferierbarkeit von Angriffen, die auf einem "eigenen" neuronalen Netz erzeugt wurden und gegen ein unbekanntes Blackbox modell funktioniern

Einschränkungen? Probleme? Rechtfertigung der Implementation eines eigenen Modells


\section{Implementierung eines eigenen Modells zur Klassifizierung von Straßenschildern (Aphrodite)}
Für die lokale Degeneration in Kapitel \ref{cha:Degeneration} wurde mithilfe Tensorflows ein eigenes Keras-Model erstellt zur Verkehrsschilderkennung. \todo{at Peter: Bezug der Aphrodite in Gradient Ascent Fooling?}

~\newline Das (am meisten verwendete) Modell \textit{Aphrodite} umfasst vier Convolutional-Layer, drei Dense-Layer und zuletzt im Ausgabelayer eine Softmax-Funktion für die 43 Klassen. Ein detaillierter Aufbau des Netzes befindet sich im Anhang\todo{Netzzusammenfassung als Tabelle in den Anhang}\todo{Link in den Anhang}.

~\newline Für das Training wurden die GTSRB-Trainings- und Test-Daten verwendet. Diese wurden um die richtige Auflösung zu erreichen auf 64x64 interpoliert. 

Da nicht sicher war, welche Interpolationsfunktion innerhalb der Remote-Schnittstelle verwendet wurde, wurde für das Training jedes Bild mehrfach interpoliert und ebenfalls mehrfach für das Training verwendet. Für die Testdaten wurde eine zufällige Interpolationsfunktion ausgesucht. 

~\newline \textit{Aphrodite} erreichte eine Genauigkeit von 96.5 \% auf die Trainingsdaten. Eine Übersicht über die Trainingsparameter findet sich im Repository unter /DegenerationCode/Training.py. \todo{Sollte man das anders schreiben? Oder packen wir das file in den Anhang?}

~\newline Der Name Aphrodite wurde gewählt, um dem ersten Modell (Model A) innerhalb des Projektes einen sprechenden Namen zu geben.

\todo{ANPE: Das ALEXNET-Model hier auch listen?}