
@article{sundararajan_axiomatic_2017,
	title = {Axiomatic {Attribution} for {Deep} {Networks}},
	url = {http://arxiv.org/abs/1703.01365},
	abstract = {We study the problem of attributing the prediction of a deep network to its input features, a problem previously studied by several other works. We identify two fundamental axioms---Sensitivity and Implementation Invariance that attribution methods ought to satisfy. We show that they are not satisfied by most known attribution methods, which we consider to be a fundamental weakness of those methods. We use the axioms to guide the design of a new attribution method called Integrated Gradients. Our method requires no modification to the original network and is extremely simple to implement; it just needs a few calls to the standard gradient operator. We apply this method to a couple of image models, a couple of text models and a chemistry model, demonstrating its ability to debug networks, to extract rules from a network, and to enable users to engage with models better.},
	urldate = {2019-01-11},
	journal = {arXiv:1703.01365 [cs]},
	author = {Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.01365},
	keywords = {Computer Science - Machine Learning}
}

@article{qin_how_2018,
	title = {How convolutional neural network see the world - {A} survey of convolutional neural network visualization methods},
	url = {http://arxiv.org/abs/1804.11191},
	abstract = {Nowadays, the Convolutional Neural Networks (CNNs) have achieved impressive performance on many computer vision related tasks, such as object detection, image recognition, image retrieval, etc. These achievements benefit from the CNNs outstanding capability to learn the input features with deep layers of neuron structures and iterative training process. However, these learned features are hard to identify and interpret from a human vision perspective, causing a lack of understanding of the CNNs internal working mechanism. To improve the CNN interpretability, the CNN visualization is well utilized as a qualitative analysis method, which translates the internal features into visually perceptible patterns. And many CNN visualization works have been proposed in the literature to interpret the CNN in perspectives of network structure, operation, and semantic concept. In this paper, we expect to provide a comprehensive survey of several representative CNN visualization methods, including Activation Maximization, Network Inversion, Deconvolutional Neural Networks (DeconvNet), and Network Dissection based visualization. These methods are presented in terms of motivations, algorithms, and experiment results. Based on these visualization methods, we also discuss their practical applications to demonstrate the significance of the CNN interpretability in areas of network design, optimization, security enhancement, etc.},
	urldate = {2019-01-11},
	journal = {arXiv:1804.11191 [cs]},
	author = {Qin, Zhuwei and Yu, Fuxun and Liu, Chenchen and Chen, Xiang},
	month = apr,
	year = {2018},
	note = {arXiv: 1804.11191},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{liu_delving_2016,
	title = {Delving into {Transferable} {Adversarial} {Examples} and {Black}-box {Attacks}},
	url = {http://arxiv.org/abs/1611.02770},
	abstract = {An intriguing property of deep neural networks is the existence of adversarial examples, which can transfer among different architectures. These transferable adversarial examples may severely hinder deep neural network-based applications. Previous works mostly study the transferability using small scale datasets. In this work, we are the first to conduct an extensive study of the transferability over large models and a large scale dataset, and we are also the first to study the transferability of targeted adversarial examples with their target labels. We study both non-targeted and targeted adversarial examples, and show that while transferable non-targeted adversarial examples are easy to find, targeted adversarial examples generated using existing approaches almost never transfer with their target labels. Therefore, we propose novel ensemble-based approaches to generating transferable adversarial examples. Using such approaches, we observe a large proportion of targeted adversarial examples that are able to transfer with their target labels for the first time. We also present some geometric studies to help understanding the transferable adversarial examples. Finally, we show that the adversarial examples generated using ensemble-based approaches can successfully attack Clarifai.com, which is a black-box image classification system.},
	urldate = {2019-01-11},
	journal = {arXiv:1611.02770 [cs]},
	author = {Liu, Yanpei and Chen, Xinyun and Liu, Chang and Song, Dawn},
	month = nov,
	year = {2016},
	note = {arXiv: 1611.02770},
	keywords = {Computer Science - Machine Learning}
}

@article{simonyan_deep_2013,
	title = {Deep {Inside} {Convolutional} {Networks}: {Visualising} {Image} {Classification} {Models} and {Saliency} {Maps}},
	shorttitle = {Deep {Inside} {Convolutional} {Networks}},
	url = {http://arxiv.org/abs/1312.6034},
	abstract = {This paper addresses the visualisation of image classification models, learnt using deep Convolutional Networks (ConvNets). We consider two visualisation techniques, based on computing the gradient of the class score with respect to the input image. The first one generates an image, which maximises the class score [Erhan et al., 2009], thus visualising the notion of the class, captured by a ConvNet. The second technique computes a class saliency map, specific to a given image and class. We show that such maps can be employed for weakly supervised object segmentation using classification ConvNets. Finally, we establish the connection between the gradient-based ConvNet visualisation methods and deconvolutional networks [Zeiler et al., 2013].},
	urldate = {2019-01-11},
	journal = {arXiv:1312.6034 [cs]},
	author = {Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
	month = dec,
	year = {2013},
	note = {arXiv: 1312.6034},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@misc{ozbulak_pytorch_2019,
	title = {Pytorch implementation of convolutional neural network adversarial attack techniques : utkuozbulak/pytorch-cnn-adversarial-attacks},
	copyright = {MIT},
	shorttitle = {Pytorch implementation of convolutional neural network adversarial attack techniques},
	url = {https://github.com/utkuozbulak/pytorch-cnn-adversarial-attacks},
	urldate = {2019-01-11},
	author = {Ozbulak, Utku},
	month = jan,
	year = {2019},
	note = {original-date: 2017-12-15T01:39:12Z}
}

@misc{anh_implementations_2019,
	title = {Implementations of some popular {Saliency} {Maps} in {Keras}: experiencor/deep-viz-keras},
	shorttitle = {Implementations of some popular {Saliency} {Maps} in {Keras}},
	url = {https://github.com/experiencor/deep-viz-keras},
	urldate = {2019-01-11},
	author = {Anh, Huynh Ngoc},
	month = jan,
	year = {2019},
	note = {original-date: 2017-06-23T08:16:07Z}
}

@article{efler_autonomes_2018,
	address = {Hamburg},
	chapter = {Mobilität},
	title = {Autonomes {Fahren}: {Das} {Ende} des {Lenkrads}},
	issn = {0044-2070},
	shorttitle = {Autonomes {Fahren}},
	url = {https://www.zeit.de/mobilitaet/2018-01/autonomes-fahren-ces-2018-deutsche-autos-volkswagen},
	abstract = {Die Elektronik-Messe CES in Las Vegas zeigt den scharfen Strategiewechsel der deutschen Autokonzerne. Volkswagen sicherte sich dafür die Hilfe aus dem Silicon Valley.},
	language = {de-DE},
	urldate = {2019-01-05},
	journal = {Die Zeit},
	author = {Efler, Marcus},
	month = jan,
	year = {2018},
	keywords = {Audi, Autohersteller, autonomes Fahren, BMW, Elektronik, Google Inc., Hyundai Motor, Las Vegas, Mercedes-Benz, Nevada, Nissan, Panasonic, Silicon Valley, Start-up, Uber, Volkswagen},
	file = {Snapshot:C\:\\Users\\Flo\\Zotero\\storage\\B6HM3VI7\\autonomes-fahren-ces-2018-deutsche-autos-volkswagen.html:text/html}
}

@misc{bmw_autonomes_nodate,
	title = {Autonomes {Fahren} - {Die} 5 {Stufen} zum selbstfahrenden {Auto}},
	url = {https://www.bmw.com/de/automotive-life/autonomes-fahren.html},
	abstract = {Jeder redet über autonomes Fahren, aber was bedeutet das eigentlich? Wie weit sind wir vom selbstfahrenden Auto entfernt und was ist bereits Realität?},
	language = {de},
	urldate = {2019-01-05},
	author = {BMW},
	file = {Snapshot:C\:\\Users\\Flo\\Zotero\\storage\\XYILRDBK\\autonomes-fahren.html:text/html}
}

@misc{bmbf-internetredaktion_auto_nodate,
	title = {Das {Auto} von morgen: autonom, sicher, effizient - {BMBF}},
	shorttitle = {Das {Auto} von morgen},
	url = {https://www.bmbf.de/de/automatisiertes-fahren-4158.html},
	abstract = {Mit rund 100 Millionen Euro fördert das Bundesforschungsministerium Projekte zum automatisierten und vernetzten Fahren. Dank der exzellenten Forschungslandschaft ist Deutschland für die intelligente Mobilität gut aufgestellt.},
	language = {de},
	urldate = {2019-01-05},
	journal = {Bundesministerium für Bildung und Forschung - BMBF},
	author = {BMBF-Internetredaktion},
	file = {Snapshot:C\:\\Users\\Flo\\Zotero\\storage\\AAGLMEGD\\automatisiertes-fahren-4158.html:text/html}
}

@book{maurer_autonomes_2015,
	address = {Berlin},
	title = {Autonomes {Fahren}: {Technische}, rechtliche und gesellschaftliche {Aspekte}},
	isbn = {978-3-662-45853-2},
	shorttitle = {Autonomes {Fahren}},
	language = {de},
	publisher = {Springer Vieweg},
	editor = {Maurer, Markus and Gerdes, J. Christian and Lenz, Barbara and Winner, Hermann},
	year = {2015},
	keywords = {Automobile driving, Automobiles, Autonomous vehicles, Driver assistance systems, Electronic equipment, Human factors, Safety measures, Social aspects, Technological innovations, Traffic safety},
	file = {Autonomes Fahren.pdf:D\:\\Dokumente\\Studium\\IT-Projekt\\Literatur\\Autonomes Fahren.pdf:application/pdf}
}

@misc{noauthor_scipy.org_nodate,
	title = {{SciPy}.org — {SciPy}.org},
	url = {https://www.scipy.org/},
	urldate = {2019-01-03},
	file = {SciPy.org — SciPy.org:C\:\\Users\\Flo\\Zotero\\storage\\QTJKXTAZ\\www.scipy.org.html:text/html}
}

@misc{noauthor_matplotlib:_nodate,
	title = {Matplotlib: {Python} plotting — {Matplotlib} 3.0.2 documentation},
	url = {https://matplotlib.org/},
	urldate = {2019-01-03},
	file = {Matplotlib\: Python plotting — Matplotlib 3.0.2 documentation:C\:\\Users\\Flo\\Zotero\\storage\\BKDD46WB\\matplotlib.org.html:text/html}
}

@misc{noauthor_opencv_nodate,
	title = {{OpenCV} library},
	url = {https://opencv.org/},
	urldate = {2019-01-03},
	file = {OpenCV library:C\:\\Users\\Flo\\Zotero\\storage\\4YQ8X5WM\\opencv.org.html:text/html}
}

@misc{noauthor_numpy_nodate,
	title = {{NumPy} — {NumPy}},
	url = {http://www.numpy.org/},
	urldate = {2019-01-03},
	file = {NumPy — NumPy:C\:\\Users\\Flo\\Zotero\\storage\\KJLEPEW6\\www.numpy.org.html:text/html}
}

@misc{noauthor_pillow_nodate,
	title = {Pillow — {Pillow} ({PIL} {Fork}) 5.3.0 documentation},
	url = {https://pillow.readthedocs.io/en/5.3.x/},
	urldate = {2019-01-03},
	file = {Pillow — Pillow (PIL Fork) 5.3.0 documentation:C\:\\Users\\Flo\\Zotero\\storage\\GR7UIPLK\\5.3.html:text/html}
}

@misc{noauthor_requests:_nodate,
	title = {Requests: {HTTP} for {Humans}™ — {Requests} 2.21.0 documentation},
	url = {http://docs.python-requests.org/en/master/},
	urldate = {2019-01-03},
	file = {Requests\: HTTP for Humans™ — Requests 2.21.0 documentation:C\:\\Users\\Flo\\Zotero\\storage\\6XVBMLAU\\master.html:text/html}
}

@misc{team_torchvision:_nodate,
	title = {torchvision: image and video datasets and models for torch deep learning},
	copyright = {BSD},
	shorttitle = {torchvision},
	url = {https://github.com/pytorch/vision},
	urldate = {2019-01-03},
	author = {Team, PyTorch Core},
	file = {Snapshot:C\:\\Users\\Flo\\Zotero\\storage\\UMXCZJC8\\torchvision.html:text/html}
}

@misc{noauthor_home_nodate,
	title = {Home - {Keras} {Documentation}},
	url = {https://keras.io/},
	urldate = {2019-01-03},
	file = {Home - Keras Documentation:C\:\\Users\\Flo\\Zotero\\storage\\MJS3LBH5\\keras.io.html:text/html}
}

@misc{noauthor_project_nodate,
	title = {Project {Jupyter}},
	url = {https://www.jupyter.org},
	abstract = {The Jupyter Notebook is a web-based interactive computing platform. The notebook combines live code, equations, narrative text, visualizations, interactive dashboards and other media.},
	urldate = {2019-01-03},
	file = {Snapshot:C\:\\Users\\Flo\\Zotero\\storage\\QZ6LMDE3\\jupyter.org.html:text/html}
}

@misc{noauthor_anaconda_nodate,
	title = {Anaconda {Accelerate} — {Anaconda} 2.0 documentation},
	url = {https://docs.continuum.io/accelerate/2.2/},
	urldate = {2019-01-03},
	file = {Anaconda Accelerate — Anaconda 2.0 documentation:C\:\\Users\\Flo\\Zotero\\storage\\3PJ36UM5\\2.html:text/html}
}

@misc{noauthor_managing_nodate,
	title = {Managing environments — {Conda} documentation},
	url = {https://conda.io/docs/user-guide/tasks/manage-environments.html},
	urldate = {2019-01-03},
	file = {Managing environments — Conda documentation:C\:\\Users\\Flo\\Zotero\\storage\\74JYM9CI\\manage-environments.html:text/html}
}

@misc{noauthor_stack_nodate,
	title = {Stack {Overflow} {Developer} {Survey} 2017},
	url = {https://stackoverflow.com/insights/survey/2017/?utm_source=so-owned&utm_medium=social&utm_campaign=dev-survey-2017&utm_content=social-share},
	abstract = {Get insights on the world’s developers from the largest and most comprehensive survey ever. Demographics. Technologies. Salaries. Career satisfaction.},
	urldate = {2019-01-03},
	journal = {Stack Overflow},
	file = {Snapshot:C\:\\Users\\Flo\\Zotero\\storage\\KF52VYAT\\2017.html:text/html}
}

@misc{india_why_2018,
	title = {Why {Python} is the most popular language used for {Machine} {Learning}},
	url = {https://medium.com/@UdacityINDIA/why-use-python-for-machine-learning-e4b0b4457a77},
	abstract = {By- Prince Patel},
	urldate = {2019-01-03},
	journal = {Medium},
	author = {India, Udacity},
	month = mar,
	year = {2018},
	file = {Snapshot:C\:\\Users\\Flo\\Zotero\\storage\\NE6J4PBA\\why-use-python-for-machine-learning-e4b0b4457a77.html:text/html}
}

@misc{noauthor_what_nodate,
	title = {What is {Python}? {Executive} {Summary}},
	shorttitle = {What is {Python}?},
	url = {https://www.python.org/doc/essays/blurb/},
	abstract = {The official home of the Python Programming Language},
	language = {en},
	urldate = {2019-01-03},
	journal = {Python.org},
	file = {Snapshot:C\:\\Users\\Flo\\Zotero\\storage\\9A7HMPY6\\blurb.html:text/html}
}

@inproceedings{nguyen_deep_2015,
	address = {Boston, MA, USA},
	title = {Deep {Neural} {Networks} {Are} {Easily} {Fooled}: {High} {Confidence} {Predictions} {For} {Unrecognizable} {Images}.pdf},
	isbn = {978-1-4673-6964-0},
	shorttitle = {Deep neural networks are easily fooled},
	url = {http://ieeexplore.ieee.org/document/7298640/},
	doi = {10.1109/CVPR.2015.7298640},
	abstract = {Deep neural networks (DNNs) have recently been achieving state-of-the-art performance on a variety of pattern-recognition tasks, most notably visual classiﬁcation problems. Given that DNNs are now able to classify objects in images with near-human-level performance, questions naturally arise as to what differences remain between computer and human vision. A recent study [30] revealed that changing an image (e.g. of a lion) in a way imperceptible to humans can cause a DNN to label the image as something else entirely (e.g. mislabeling a lion a library). Here we show a related result: it is easy to produce images that are completely unrecognizable to humans, but that state-of-theart DNNs believe to be recognizable objects with 99.99\% conﬁdence (e.g. labeling with certainty that white noise static is a lion). Speciﬁcally, we take convolutional neural networks trained to perform well on either the ImageNet or MNIST datasets and then ﬁnd images with evolutionary algorithms or gradient ascent that DNNs label with high conﬁdence as belonging to each dataset class. It is possible to produce images totally unrecognizable to human eyes that DNNs believe with near certainty are familiar objects, which we call “fooling images” (more generally, fooling examples). Our results shed light on interesting differences between human vision and current DNNs, and raise questions about the generality of DNN computer vision.},
	language = {en},
	urldate = {2018-10-25},
	booktitle = {2015 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Nguyen, Anh and Yosinski, Jason and Clune, Jeff},
	month = jun,
	year = {2015},
	pages = {427--436},
	file = {Deep Neural Networks Are Easily Fooled\: High Confidence Predictions For Unrecognizable Images.pdf:C\:\\Users\\Flo\\Zotero\\storage\\Q222R6Z6\\Deep Neural Networks Are Easily Fooled High Confidence Predictions For Unrecognizable Images.pdf:application/pdf}
}

@article{goodfellow_generative_2014,
	title = {Generative {Adversarial} {Networks}.pdf},
	url = {http://arxiv.org/abs/1406.2661},
	abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
	urldate = {2018-10-25},
	journal = {arXiv:1406.2661 [cs, stat]},
	author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	month = jun,
	year = {2014},
	note = {arXiv: 1406.2661},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:C\:\\Users\\Flo\\Zotero\\storage\\X6QALYJA\\1406.html:text/html;Generative Adversarial Networks.pdf:C\:\\Users\\Flo\\Zotero\\storage\\JFTQACJX\\Generative Adversarial Networks.pdf:application/pdf}
}

@article{papernot_+_2016,
	title = {(+) {Practical} {Black}-box {Attacks} {Against} {Machine} {Learning}.pdf},
	url = {http://arxiv.org/abs/1602.02697},
	abstract = {Machine learning (ML) models, e.g., deep neural networks (DNNs), are vulnerable to adversarial examples: malicious inputs modified to yield erroneous model outputs, while appearing unmodified to human observers. Potential attacks include having malicious content like malware identified as legitimate or controlling vehicle behavior. Yet, all existing adversarial example attacks require knowledge of either the model internals or its training data. We introduce the first practical demonstration of an attacker controlling a remotely hosted DNN with no such knowledge. Indeed, the only capability of our black-box adversary is to observe labels given by the DNN to chosen inputs. Our attack strategy consists in training a local model to substitute for the target DNN, using inputs synthetically generated by an adversary and labeled by the target DNN. We use the local substitute to craft adversarial examples, and find that they are misclassified by the targeted DNN. To perform a real-world and properly-blinded evaluation, we attack a DNN hosted by MetaMind, an online deep learning API. We find that their DNN misclassifies 84.24\% of the adversarial examples crafted with our substitute. We demonstrate the general applicability of our strategy to many ML techniques by conducting the same attack against models hosted by Amazon and Google, using logistic regression substitutes. They yield adversarial examples misclassified by Amazon and Google at rates of 96.19\% and 88.94\%. We also find that this black-box attack strategy is capable of evading defense strategies previously found to make adversarial example crafting harder.},
	urldate = {2018-10-14},
	journal = {arXiv:1602.02697 [cs]},
	author = {Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian and Jha, Somesh and Celik, Z. Berkay and Swami, Ananthram},
	month = feb,
	year = {2016},
	note = {arXiv: 1602.02697},
	keywords = {Computer Science - Machine Learning, Computer Science - Cryptography and Security},
	annote = {Comment: Proceedings of the 2017 ACM Asia Conference on Computer and Communications Security, Abu Dhabi, UAE},
	file = {arXiv.org Snapshot:C\:\\Users\\Flo\\Zotero\\storage\\XFAPL8ZA\\1602.html:text/html;Practical Black-box Attacks Against Machine Learning.pdf:C\:\\Users\\Flo\\Zotero\\storage\\ZXT6TZJQ\\Practical Black-box Attacks Against Machine Learning.pdf:application/pdf}
}

@article{springenberg_striving_2014,
	title = {Striving for {Simplicity}: {The} {All} {Convolutional} {Net}},
	shorttitle = {Striving for {Simplicity}},
	url = {http://arxiv.org/abs/1412.6806},
	abstract = {Most modern convolutional neural networks (CNNs) used for object recognition are built using the same principles: Alternating convolution and max-pooling layers followed by a small number of fully connected layers. We re-evaluate the state of the art for object recognition from small images with convolutional networks, questioning the necessity of different components in the pipeline. We find that max-pooling can simply be replaced by a convolutional layer with increased stride without loss in accuracy on several image recognition benchmarks. Following this finding -- and building on other recent work for finding simple network structures -- we propose a new architecture that consists solely of convolutional layers and yields competitive or state of the art performance on several object recognition datasets (CIFAR-10, CIFAR-100, ImageNet). To analyze the network we introduce a new variant of the "deconvolution approach" for visualizing features learned by CNNs, which can be applied to a broader range of network structures than existing approaches.},
	urldate = {2019-01-11},
	journal = {arXiv:1412.6806 [cs]},
	author = {Springenberg, Jost Tobias and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, Martin},
	month = dec,
	year = {2014},
	note = {arXiv: 1412.6806},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing}
}

@book{heistermann2013genetische,
	title={Genetische Algorithmen: Theorie und Praxis evolution{\"a}rer Optimierung},
	author={Heistermann, Jochen},
	volume={9},
	year={2013},
	pages={16--24},
	publisher={Springer-Verlag}
}
@book{gerdes2013evolutionare,
	title={Evolution{\"a}re Algorithmen: Genetische Algorithmen—Strategien und Optimierungsverfahren—Beispielanwendungen},
	author={Gerdes, Ingrid and Klawonn, Frank and Kruse, Rudolf},
	pages={33--36},
	year={2013},
	publisher={Springer-Verlag}
}

@article{schoneburg1994genetische,
	title={Genetische Algorithmen und Evolutionsstrategien},
	author={Sch{\"o}neburg, Eberhard and Heinzmann, Frank and Feddersen, Sven and others},
	journal={Bonn: Addison-Wesley},
	pages={185--218},
	year={1994}
}

@misc{mstay,
	title = {microsofts-new-ai-powered-bot-tay-answers-your-tweets-and-chats-on-groupme-and-kik},
	url = {https://techcrunch.com/2016/03/23/microsofts-new-ai-powered-bot-tay-answers-your-tweets-and-chats-on-groupme-and-kik/},
	date = {2016-03-23},
	urldate = {2019-01-12},
	author = {Sarah Perez}
}
@misc{mstaydown,
	title = {microsoft-silences-its-new-a-i-bot-tay-after-twitter-users-teach-it-racism/},
	url = {https://techcrunch.com/2016/03/24/microsoft-silences-its-new-a-i-bot-tay-after-twitter-users-teach-it-racism/},
	date = {2016-03-24},
	urldate = {2019-01-12},
	author = {Sarah Perez}
}
@article{DBLP:journals/corr/HuangPGDA17,
	author    = {Sandy H. Huang and
	Nicolas Papernot and
	Ian J. Goodfellow and
	Yan Duan and
	Pieter Abbeel},
	title     = {Adversarial Attacks on Neural Network Policies},
	journal   = {CoRR},
	volume    = {abs/1702.02284},
	year      = {2017},
	url       = {http://arxiv.org/abs/1702.02284},
	archivePrefix = {arXiv},
	eprint    = {1702.02284},
	timestamp = {Mon, 13 Aug 2018 16:48:47 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/HuangPGDA17},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{VertrauenTechnik, 
	title = {Ein Unfall, der am Branchen-Versprechen nagt},
	author = {dpa,ZDF},
	urldate={2019-01-12},
	date={2018-03-20},
	url = {https://www.zdf.de/nachrichten/heute/uber-unfall-schlecht-fuer-vertrauen-in-technik-100.html}
}